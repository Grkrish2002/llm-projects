{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQMVxdpjfHPgDHWuO82CkU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Grkrish2002/llm-projects/blob/main/LLM_Query_Interface.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4CBx6Qhy8lf"
      },
      "outputs": [],
      "source": [
        "!pip install -q streamlit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "9df0N9E7z0W-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cohere"
      ],
      "metadata": {
        "id": "k_7uYNSQGR6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from openai import OpenAI\n",
        "import cohere\n",
        "\n",
        "openai_api_key = \"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\"\n",
        "cohere_api_key = \"jCh2tndXHqNsrT5sdIwV6loR52Tji8EE6DyNva0w\"\n",
        "\n",
        "GPT_MODEL = \"gpt-3.5-turbo\"\n",
        "COHERE_MODEL = 'command'\n",
        "\n",
        "# from google.colab import userdata\n",
        "# openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "openaiclient = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "      api_key=openai_api_key\n",
        ")\n",
        "\n",
        "co = cohere.Client(cohere_api_key)\n",
        "\n",
        "st.title(\"LLM Prompt Interface\")\n",
        "system_message = \"You are a helpful assistant that generates code in various programming languages\"\n",
        "user_request = st.text_area(\"Enter the prompt\", key=1)\n",
        "\n",
        "messages = [\n",
        "  {\"role\": \"system\", \"content\": system_message},\n",
        "  {\"role\": \"user\", \"content\": user_request}\n",
        "]\n",
        "\n",
        "SEED = 12345\n",
        "\n",
        "st.write('<style>div.row-widget.stRadio > div{flex-direction:row;} </style>', unsafe_allow_html=True)\n",
        "\n",
        "llm_to_use = st.radio(\"LLM to use:\",('OpenAI','Cohere','PaLM'),key=11)\n",
        "\n",
        "if st.button(\"Run Prompt\"):\n",
        "  if llm_to_use == \"OpenAI\":\n",
        "    openai_response = openaiclient.chat.completions.create(\n",
        "       model = GPT_MODEL,\n",
        "       messages = messages,\n",
        "       seed=SEED,\n",
        "       max_tokens=200,\n",
        "       temperature=0.7\n",
        "     )\n",
        "    # response_content = openai_response[\"choices\"][0][\"message\"][\"content\"]\n",
        "    response_content = openai_response.choices[0].message\n",
        "    st.markdown(\"Response:\")\n",
        "    st.write(response_content)\n",
        "\n",
        "  elif llm_to_use == \"Cohere\":\n",
        "    cohere_response = co.generate(\n",
        "      model=COHERE_MODEL,\n",
        "      prompt=user_request,\n",
        "      max_tokens=1000\n",
        "     )\n",
        "    response_content = 'cohere_response: {}'.format(cohere_response.generations[0].text)\n",
        "    st.markdown(\"Response:\")\n",
        "    st.write(response_content)\n",
        "\n",
        "  elif llm_to_use == \"PaLM\":\n",
        "    st.write(\"PaLM not configured\")"
      ],
      "metadata": {
        "id": "sssFdaF0zK_G",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a62d6e34-b277-4dd8-af1e-8fce11993e05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel"
      ],
      "metadata": {
        "id": "zx2Xvt8gzZbG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65018d3d-29c0-4c09-f751-f9af6b5b0f3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25h+ localtunnel@2.0.2\n",
            "updated 1 package and audited 36 packages in 0.457s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found 2 \u001b[93mmoderate\u001b[0m severity vulnerabilities\n",
            "  run `npm audit fix` to fix them, or `npm audit` for details\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "tPi7Dvtkzb9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "x8KQkIcBzeFG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27075d87-6e56-4ae8-c954-c3bff9f5d391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 1.447s\n",
            "your url is: https://six-foxes-battle.loca.lt\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}